# ============================================================================
# Latent Space Reasoning Engine - Configuration Template
# ============================================================================
#
# This file contains all available configuration options with detailed explanations.
# Copy to config.yaml and customize for your needs.
#
# Usage: latent-reason run "your query" --config config.yaml
#
# Quick start tips:
# - For best quality: Use Qwen/Qwen3-4B with 8+ chains and 15+ generations
# - For speed: Use Qwen/Qwen3-0.6B with 5 chains and 10 generations
# - For CPU-only: Use Qwen/Qwen3-0.6B with device: "cpu"
# ============================================================================

# ============================================================================
# ENCODER CONFIGURATION - The foundation model
# ============================================================================
encoder:
  # Model selection - choose based on your hardware and quality needs
  #
  # Recommended models (all tested and working):
  #   Qwen/Qwen3-4B     - Best quality, needs ~8GB VRAM
  #   Qwen/Qwen3-1.7B   - Great balance, needs ~4GB VRAM
  #   Qwen/Qwen3-0.6B   - Fast iteration, needs ~2GB VRAM, CPU-friendly
  #   microsoft/phi-2   - Alternative option, ~6GB VRAM
  #   ibm-granite/granite-4.0-h-1b - Compact alternative, ~2GB VRAM
  #
  # You can also use local model paths if you have models downloaded
  model: "Qwen/Qwen3-0.6B"

  # Hidden layer extraction settings
  # -4 means 4th layer from the end, which usually gives the best latent representations
  # Try -2, -4, -6, or -8 if you want to experiment
  layer: -4

  # Sequence pooling method - how to combine token representations into a single vector
  # "mean" - Average all tokens (recommended for most cases)
  # "last" - Use only the last token
  # "cls"  - Use the classification token (if model has one)
  pooling: "mean"

  # Hardware settings
  # "auto" - Automatically choose GPU if available, otherwise CPU
  # "cuda" - Use default GPU
  # "cuda:0", "cuda:1" - Use specific GPU
  # "cpu" - Force CPU usage (slower but works without GPU)
  device: "auto"

  # Maximum input length in tokens
  # Longer inputs need more memory but can handle more complex queries
  # 2048 is good for most queries, increase to 4096 for very long inputs
  max_length: 2048

# ============================================================================
# JUDGE CONFIGURATION - Quality evaluation and improvement
# ============================================================================
judges:
  # Scorers evaluate the quality of latent vectors during evolution
  # Multiple scorers can be used and their outputs will be combined
  scorers:
    # OPTION 1: Trained latent scorer (recommended)
    # This uses a neural network trained specifically to predict response quality
    # from latent vectors. It's fast and well-calibrated for evolution.
    - type: "trained_latent"
      checkpoint: "checkpoints/latent_scorer/final_model.pt"  # Path to trained model
      latent_dim: 1024  # Must match the scorer's expected input dimension

    # OPTION 2: Semantic scorer (alternative)
    # This uses cosine similarity between query and response embeddings
    # No training needed, but may be less accurate than trained scorer
    # - type: "semantic"
    #   model: "sentence-transformers/all-MiniLM-L6-v2"  # Embedding model
    #   layer: -1  # Which layer to extract embeddings from

  # Modifiers suggest improvements to latent vectors (optional)
  # They analyze the current latent and suggest directions for mutation
  # Leave empty to disable modification suggestions (faster but less directed)
  modifiers:
    # Use a smaller/faster model than the encoder for speed
    - model: "Qwen/Qwen3-0.6B"
      layers: [-8, -4]  # Hidden layers to extract modification signals from

  # Judge panel behavior
  aggregation: "mean"  # How to combine multiple scorer outputs: mean, weighted, max, min
  calibrate: true      # Normalize scores to zero-mean for better evolution dynamics

# ============================================================================
# EVOLUTION CONFIGURATION - The heart of the optimization process
# ============================================================================
evolution:
  # Population size - number of parallel reasoning chains to evolve
  # More chains = more exploration but slower
  # Recommended: 5-8 for most cases, 10+ for complex queries
  chains: 8

  # Maximum evolution generations to run
  # More generations = more refinement but slower
  # Most queries converge in 10-20 generations
  generations: 20

  # Initial mutation temperature - controls exploration vs exploitation
  # Higher values = more exploration, lower = more exploitation
  # 0.5 is a good balance, try 0.3 for exploitation or 0.8 for exploration
  temperature: 0.5

  # Temperature decay per generation (simulated annealing)
  # 0.95 means temperature reduces by 5% each generation
  # This gradually shifts from exploration to exploitation
  temperature_decay: 0.95

  # Minimum score threshold for survival
  # Chains below this score are eliminated regardless of ranking
  min_viable_score: 0.1

  # SELECTION - Which chains survive to the next generation
  selection:
    # Selection strategies:
    # "elitist"    - Always keep top performers + some random (recommended)
    # "tournament" - Random tournaments between pairs
    # "rank"       - Simple top-N selection
    # "roulette"   - Probability proportional to fitness
    strategy: "elitist"

    # How many chains to keep each generation
    survivors: 5

    # For elitist strategy: always keep this many top performers
    elite: 2

  # MUTATION - How to modify surviving chains
  mutation:
    # Mutation strategies:
    # "gaussian"  - Random Gaussian noise
    # "directed"  - Follow modifier suggestions + some randomness (recommended)
    # "adaptive"  - Adjust mutation strength based on progress
    strategy: "adaptive"

    # Trust level for modifier suggestions (0=ignore, 1=fully trust)
    # 0.7 means 70% modifier direction, 30% random exploration
    trust: 0.7

  # CROSSOVER - Combining successful chains
  crossover:
    # Crossover strategies:
    # "weighted"      - Weight by fitness scores (recommended)
    # "mean"          - Simple average
    # "interpolation" - Random interpolation
    strategy: "weighted"

    # Minimum population diversity required for crossover
    # If chains are too similar, skip crossover to avoid premature convergence
    threshold: 0.3

  # MERGING - Combine similar chains to avoid redundancy
  merge:
    # Cosine similarity threshold for merging chains
    # 0.9 means chains with >90% similarity get merged
    threshold: 0.9

  # CONVERGENCE - Early stopping criteria
  convergence:
    # Score threshold for early stopping
    # Stop if best chain reaches this quality score
    threshold: 0.95

    # Patience: generations without improvement before stopping
    # Prevents wasting computation when evolution has plateaued
    patience: 5

# ============================================================================
# Budget Configuration
# ============================================================================
budget:
  # Maximum judge evaluations
  max_evaluations: 500

  # Maximum wall time in seconds (null = unlimited)
  max_time: null

# ============================================================================
# Synthesis Configuration
# ============================================================================
synthesis:
  # Decoder model (null = use encoder)
  decoder: null

  # Frontier model for synthesis (if needed)
  model: "gemini-2.5-flash"

  # How many chains to decode
  max_survivors: 5

  # Maximum output tokens
  max_tokens: 2048

  # Sampling temperature for decoding
  temperature: 0.7

# ============================================================================
# Output Configuration
# ============================================================================
output:
  # Verbosity: silent, minimal, normal, verbose, debug
  verbosity: "normal"

  # Output format: text, json, markdown
  format: "text"

  # Save evolution history
  save_history: false

  # Path for history files
  history_path: null

# ============================================================================
# Benchmark Configuration (for evaluation)
# ============================================================================
benchmark:
  # Model for A/B evaluation
  judge_model: "gemini-2.5-flash"

  # Randomize output order for blind judging
  blind: true

  # Judge temperature (0 = deterministic)
  temperature: 0
